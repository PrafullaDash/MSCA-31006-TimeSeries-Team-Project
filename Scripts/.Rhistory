forecast(m1,h=90)
autoplot(forecast(m1,h=90))
#checking the forecast
accuracy(forecast(m1,h=90),diff(Google_test))
#checking the forecast
accuracy(forecast(m1,h=90),diff(novela_test))
checkresiduals(m1)
autoplot(forecast(m1,h=90))
#load libraries
# visualization
library('ggplot2')
# data manipulation
library('dplyr')
library('readr')
library('imputeTS')
#time series
library('fpp')
library('forecast')
#importing the data and considering just one page
train_1 <- read.csv("~/Desktop/UChicago/Quarters/03-Quarters/Data/TS/web-traffic-time-series-forecasting/train_1.csv", header = TRUE, row.names = 1,sep = ",",skip =0)
#Tech <- data.frame(train_1[c("Google_zh.wikipedia.org_all-access_spider","Apple_II_zh.wikipedia.org_all-access_spider","Facebook_zh.wikipedia.org_all-access_spider","YouTube_zh.wikipedia.org_all-access_spider","Android_zh.wikipedia.org_all-access_spider"),])
novela <- data.matrix(train_1[c("ASCII_zh.wikipedia.org_all-access_spider"),])
#dropping the colnames and creating a time series object
dimnames(novela)<-NULL
novela<-array(novela)
head(novela)
length(novela)
plot(novela,type='l')
#creating a time series object
novela_ts<-ts(novela,frequency = 365.25,start = c(2015, 7, 1))
novela_ts
autoplot(novela_ts,ylab="1984 daily traffic",xlab="Day")
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-12-31"), by = "day")
time_index
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-12-31"), by = "day")
time_index
novela_ts <- xts(novela, order.by =time_index ,frequency = 365.25)
library(xts)
novela_ts <- xts(novela, order.by =time_index ,frequency = 365.25)
novela_ts
autoplot(novela_ts,ylab="1984 daily traffic",xlab="Day")
#load libraries
# visualization
library('ggplot2')
# data manipulation
library('dplyr')
library('readr')
library('imputeTS')
#time series
library('fpp')
library('forecast')
library(xts)
#importing the data and considering just one page
train_1 <- read.csv("~/Desktop/UChicago/Quarters/03-Quarters/Data/TS/web-traffic-time-series-forecasting/train_1.csv", header = TRUE, row.names = 1,sep = ",",skip =0)
#Tech <- data.frame(train_1[c("Google_zh.wikipedia.org_all-access_spider","Apple_II_zh.wikipedia.org_all-access_spider","Facebook_zh.wikipedia.org_all-access_spider","YouTube_zh.wikipedia.org_all-access_spider","Android_zh.wikipedia.org_all-access_spider"),])
novela <- data.matrix(train_1[c("ASCII_zh.wikipedia.org_all-access_spider"),])
#dropping the colnames and creating a time series object
dimnames(novela)<-NULL
novela<-array(novela)
head(novela)
length(novela)
plot(novela,type='l')
#creating a time series object
#novela_ts<-ts(novela,frequency = 365.25,start = c(2015, 7, 1))
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-12-31"), by = "day")
novela_ts <- xts(novela, order.by =time_index ,frequency = 365.25)
novela_ts
autoplot(novela_ts,ylab="1984 daily traffic",xlab="Day")
#splitting data into test and train
novela_train<-novela_ts['2015-07-01/2016-08-31']
novela_test<-novela_ts['2016-09-01/2016-12-31']
tsdisplay(novela_train)
tsdisplay(novela_test)
#requirement for transformation
BoxCox.lambda(novela_train)
autoplot(novela_train)
ggAcf(novela_train)
ggPacf(novela_train)
#testing stationary
kpss.test(novela_train)
#Therefore, it is non stationary and we need to difference it
novela_train_diff <- diff(novela_train)
kpss.test(novela_train_diff)
tsdisplay(novela_train_diff)
#forecast horizon
h<-90
#forecast horizon
h<-120
#naive forecasts
Model_Mean <- meanf(novela_train_diff, h)
Model_Naive <- naive(novela_train_diff, h)
Model_SNaive <- snaive(novela_train_diff,h)
Model_Drift <- rwf(novela_train_diff, h, drift=TRUE)
#Naive forecast
autoplot(diff(novela_train_diff)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
Model_SNaive <- snaive(novela_train_diff)
#forecast horizon
h<-90
#naive forecasts
Model_Mean <- meanf(novela_train_diff, h)
Model_Naive <- naive(novela_train_diff, h)
Model_SNaive <- snaive(novela_train_diff,h)
#Naive forecast
autoplot(diff(novela_train_diff)) +
#  autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Naive forecast
autoplot(diff(novela_train_diff)) +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#naive forecasts
Model_Mean <- meanf(novela_train_diff, h)
Model_Naive <- naive(novela_train_diff, h)
Model_SNaive <- snaive(novela_train_diff,h)
#naive forecasts
Model_Mean <- meanf(novela_train, h)
Model_Naive <- naive(novela_train, h)
Model_SNaive <- snaive(novela_train,h)
Model_Drift <- rwf(novela_train, h, drift=TRUE)
#Naive forecast
autoplot(diff(novela_train)) +
#  autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Naive forecast
autoplot(diff(novela_train)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Naive forecast
autoplot(diff(novela_train)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve")
#Naive forecast
autoplot(diff(novela_train))
Model_Mean
#naive forecasts
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-08-31"), by = "day")
Model_Mean <- xts(meanf(novela_train, h),time_index,frequency = 365.25)
length(time_index)
nrow(Model_Mean)
nrow(Model_Naive)
length(Model_Naive)
#naive forecasts
Model_Mean <- meanf(novela_train, h)
Model_Naive <- naive(novela_train, h)
Model_SNaive <- snaive(novela_train,h)
Model_Drift <- rwf(novela_train, h, drift=TRUE)
Model_Mean
#Naive forecast
autoplot(diff(novela_train)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Naive forecast
autoplot(novela_train) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Out of sample metrics-test
accuracy(Model_Mean,diff(novela_test))
#Building an ARIMA model
auto.arima(novela_train,seasonal = TRUE,lambda = 'auto')
m1<-Arima(novela_train,lambda = 'auto',order=c(0,1,2))
checkresiduals(m1)
forecast(m1,h=90)
autoplot(forecast(m1,h=90))
#checking the forecast
accuracy(forecast(m1,h=90),diff(novela_test))
#Building an ARIMA model
auto.arima(novela_train,seasonal = TRUE,lambda = 'auto')
m1<-Arima(novela_train,lambda = 'auto',order=c(2,1,3),include.drift = TRUE)
checkresiduals(m1)
forecast(m1,h=90)
autoplot(forecast(m1,h=90))
#naive forecasts
Model_Mean <- meanf(novela_train, h)
Model_Mean
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-08-31"), by = "day")
length(time_index)
#forecast horizon
h<-428
#naive forecasts
Model_Mean <- meanf(novela_train, h)
Model_Naive <- naive(novela_train, h)
Model_SNaive <- snaive(novela_train,h)
Model_Drift <- rwf(novela_train, h, drift=TRUE)
Model_Mean
#Naive forecast
autoplot(novela_train) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
Model_Mean<-xts(Model_Mean,order.by =time_index ,frequency = 365.25)
Model_Mean
Model_Mean$mean
Model_Mean<-xts(Model_Mean$mean,order.by =time_index ,frequency = 365.25)
#Naive forecast
autoplot(novela_train)
Model_Mean$mean
Model_Mean
#Naive forecast
autoplot(novela_train)
Model_Mean<-xts(Model_Mean$mean,order.by =time_index ,frequency = 365.25)
Model_Mean
#Naive forecast
autoplot(novela_train)+
autolayer(Model_Mean$mean, series="Mean")
library('xts')
library('zoo')
#Naive forecast
autoplot(novela_train)+
autolayer(Model_Mean$mean, series="Mean")
#naive forecasts
Model_Mean <- meanf(novela_train, h)
#Naive forecast
autoplot(novela_train)+
autolayer(Model_Mean$mean, series="Mean")
#Naive forecast
autoplot(ts(novela_train))+
autolayer(Model_Mean$mean, series="Mean")
#splitting data into test and train
novela_train<-ts(novela_ts['2015-07-01/2016-08-31'])
novela_test<-ts(novela_ts['2016-09-01/2016-12-31'])
tsdisplay(novela_train)
tsdisplay(novela_test)
#requirement for transformation
BoxCox.lambda(novela_train)
autoplot(novela_train)
ggAcf(novela_train)
ggPacf(novela_train)
#testing stationary
kpss.test(novela_train)
#Therefore, it is non stationary and we need to difference it
novela_train_diff <- diff(novela_train)
kpss.test(novela_train_diff)
tsdisplay(novela_train_diff)
#forecast horizon
h<-428
#naive forecasts
Model_Mean <- meanf(novela_train, h)
Model_Naive <- naive(novela_train, h)
Model_SNaive <- snaive(novela_train,h)
Model_Drift <- rwf(novela_train, h, drift=TRUE)
#Naive forecast
autoplot(novela_train)+
autolayer(Model_Mean$mean, series="Mean")
#naive forecasts
Model_Mean <- meanf(novela_train, h)
Model_Naive <- naive(novela_train, h)
Model_SNaive <- snaive(novela_train,h)
Model_Drift <- rwf(novela_train, h, drift=TRUE)
#Naive forecast
autoplot(diff(Google_train_diff)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Naive forecast
autoplot(diff(novela_train)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
Model_SNaive <- snaive(novela_train,h)
#Naive forecast
autoplot(diff(novela_train)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Out of sample metrics-test
accuracy(Model_Mean,diff(novela_test))
#Out of sample metrics-test
accuracy(Model_Mean,novela_test)
Model_Mean
novela_test
#splitting data into test and train
novela_train<-novela_ts['2015-07-01/2016-08-31']
novela_test<-novela_ts['2016-09-01/2016-12-31']
tsdisplay(novela_train)
tsdisplay(novela_test)
#requirement for transformation
BoxCox.lambda(novela_train)
autoplot(novela_train)
ggAcf(novela_train)
ggPacf(novela_train)
#testing stationary
kpss.test(novela_train)
#Therefore, it is non stationary and we need to difference it
novela_train_diff <- diff(novela_train)
kpss.test(novela_train_diff)
tsdisplay(novela_train_diff)
#forecast horizon
h<-428
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-08-31"), by = "day")
#naive forecasts
novela_train_new<-ts(novela_ts['2015-07-01/2016-08-31'])
novela_test_new<-ts(novela_ts['2016-09-01/2016-12-31'])
Model_Mean <- meanf(novela_train_new, h)
Model_Naive <- naive(novela_train_new, h)
Model_SNaive <- snaive(novela_train_new,h)
Model_Drift <- rwf(novela_train_new, h, drift=TRUE)
#Naive forecast
autoplot(diff(novela_train_new)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Out of sample metrics-test
accuracy(Model_Mean,novela_test)
accuracy(Model_Naive,diff(novela_test))
accuracy(Model_SNaive,diff(novela_test))
accuracy(Model_Drift,diff(novela_test))
#Building an ARIMA model
auto.arima(novela_train,seasonal = TRUE,lambda = 'auto')
m1<-Arima(novela_train,lambda = 'auto',order=c(2,1,3),include.drift = TRUE)
checkresiduals(m1)
forecast(m1,h=90)
#checking the forecast
accuracy(forecast(m1,h=90),novela_test)
#Building an ARIMA model
auto.arima(novela_train,seasonal = TRUE,lambda = 'auto')
m1<-Arima(novela_train,lambda = 'auto',order=c(2,1,3),include.drift = TRUE)
checkresiduals(m1)
forecast(m1,h=428)
autoplot(forecast(m1,h=428))
#checking the forecast
accuracy(forecast(m1,h=428),novela_test)
#load libraries
# visualization
library('ggplot2')
# data manipulation
library('dplyr')
library('readr')
library('imputeTS')
#time series
library('fpp')
library('forecast')
library('xts')
library('zoo')
#importing the data and considering just one page
train_1 <- read.csv("~/Desktop/UChicago/Quarters/03-Quarters/Data/TS/web-traffic-time-series-forecasting/train_1.csv", header = TRUE, row.names = 1,sep = ",",skip =0)
#Tech <- data.frame(train_1[c("Google_zh.wikipedia.org_all-access_spider","Apple_II_zh.wikipedia.org_all-access_spider","Facebook_zh.wikipedia.org_all-access_spider","YouTube_zh.wikipedia.org_all-access_spider","Android_zh.wikipedia.org_all-access_spider"),])
novela <- data.matrix(train_1[c("ASCII_zh.wikipedia.org_all-access_spider"),])
#dropping the colnames and creating a time series object
dimnames(novela)<-NULL
novela<-array(novela)
head(novela)
length(novela)
plot(novela,type='l')
#creating a time series object
#novela_ts<-ts(novela,frequency = 365.25,start = c(2015, 7, 1))
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-12-31"), by = "day")
novela_ts <- xts(novela, order.by =time_index ,frequency = 365.25)
novela_ts
autoplot(novela_ts,ylab="1984 daily traffic",xlab="Day")
#splitting data into test and train
novela_train<-novela_ts['2015-07-01/2016-08-31']
novela_test<-novela_ts['2016-09-01/2016-12-31']
tsdisplay(novela_train)
tsdisplay(novela_test)
#naive forecasts
novela_train_new<-ts(novela_ts['2015-07-01/2016-08-31'])
novela_test_new<-ts(novela_ts['2016-09-01/2016-12-31'])
#splitting data into test and train
novela_train<-novela_ts['2015-07-01/2016-08-31']
novela_test<-novela_ts['2016-09-01/2016-12-31']
tsdisplay(novela_train)
tsdisplay(novela_test)
#creating a time series object
#novela_ts<-ts(novela,frequency = 365.25,start = c(2015, 7, 1))
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-12-31"), by = "day")
novela_ts <- xts(novela, order.by =time_index ,frequency = 365)
novela_ts
autoplot(novela_ts,ylab="1984 daily traffic",xlab="Day")
#splitting data into test and train
novela_train<-novela_ts['2015-07-01/2016-08-31']
novela_test<-novela_ts['2016-09-01/2016-12-31']
tsdisplay(novela_train)
tsdisplay(novela_test)
novela_ts
#creating a time series object
#novela_ts<-ts(novela,frequency = 365.25,start = c(2015, 7, 1))
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-12-31"), by = "day")
novela_ts <- xts(novela, order.by =time_index ,frequency = 365.25)
novela_ts
autoplot(novela_ts,ylab="1984 daily traffic",xlab="Day")
#splitting data into test and train
novela_train<-xts(novela_ts['2015-07-01/2016-08-31'])
novela_test<-novela_ts['2016-09-01/2016-12-31']
tsdisplay(novela_train)
tsdisplay(novela_test)
#load libraries
# visualization
library('ggplot2')
# data manipulation
library('dplyr')
library('readr')
library('imputeTS')
#time series
library('fpp')
library('forecast')
library('xts')
library('zoo')
#importing the data and considering just one page
train_1 <- read.csv("~/Desktop/UChicago/Quarters/03-Quarters/Data/TS/web-traffic-time-series-forecasting/train_1.csv", header = TRUE, row.names = 1,sep = ",",skip =0)
#Tech <- data.frame(train_1[c("Google_zh.wikipedia.org_all-access_spider","Apple_II_zh.wikipedia.org_all-access_spider","Facebook_zh.wikipedia.org_all-access_spider","YouTube_zh.wikipedia.org_all-access_spider","Android_zh.wikipedia.org_all-access_spider"),])
novela <- data.matrix(train_1[c("ASCII_zh.wikipedia.org_all-access_spider"),])
#dropping the colnames and creating a time series object
dimnames(novela)<-NULL
novela<-array(novela)
head(novela)
length(novela)
plot(novela,type='l')
#creating a time series object
#novela_ts<-ts(novela,frequency = 365.25,start = c(2015, 7, 1))
time_index <- seq(from = as.POSIXct("2015-07-01"),
to = as.POSIXct("2016-12-31"), by = "day")
novela_ts <- xts(novela, order.by =time_index ,frequency = 365.25)
novela_ts
autoplot(novela_ts,ylab="1984 daily traffic",xlab="Day")
#splitting data into test and train
novela_train<-novela_ts['2015-07-01/2016-08-31']
novela_test<-novela_ts['2016-09-01/2016-12-31']
tsdisplay(novela_train)
tsdisplay(novela_test)
#requirement for transformation
BoxCox.lambda(novela_train)
autoplot(novela_train)
ggAcf(novela_train)
ggPacf(novela_train)
#testing stationary
kpss.test(novela_train)
#Therefore, it is non stationary and we need to difference it
novela_train_diff <- diff(novela_train)
kpss.test(novela_train_diff)
tsdisplay(novela_train_diff)
#forecast horizon
h<-428
#naive forecasts
novela_train_new<-ts(novela_ts['2015-07-01/2016-08-31'])
novela_test_new<-ts(novela_ts['2016-09-01/2016-12-31'])
Model_Mean <- meanf(novela_train_new, h)
Model_Naive <- naive(novela_train_new, h)
Model_SNaive <- snaive(novela_train_new,h)
Model_Drift <- rwf(novela_train_new, h, drift=TRUE)
#Naive forecast
autoplot(diff(novela_train_new)) +
autolayer(Model_SNaive$mean, series="Seasonal naïve") +
autolayer(Model_Mean$mean, series="Mean") +
autolayer(Model_Naive$mean, series="Naïve") +
autolayer(Model_Drift$mean, series="Drift") +
ggtitle("Forecasts for daily Google Wikepedia Page") +
xlab("Days") + ylab("Google traffic")
#Out of sample metrics-test
accuracy(Model_Mean,novela_test)
accuracy(Model_Naive,diff(novela_test))
accuracy(Model_SNaive,diff(novela_test))
accuracy(Model_Drift,diff(novela_test))
#Building an ARIMA model
auto.arima(novela_train,seasonal = TRUE,lambda = 'auto')
m1<-Arima(novela_train,lambda = 'auto',order=c(2,1,3),include.drift = TRUE)
checkresiduals(m1)
forecast(m1,h=428)
autoplot(forecast(m1,h=428))
#checking the forecast
accuracy(forecast(m1,h=428),novela_test)
