---
title: "ARIMA_model_initial"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Here, we apply the ARMA model for the first wikipedia page - 2NE1_zh.wikipedia.org

```{r workdirimp, echo=TRUE, message=FALSE, warning=FALSE}
# basic imports
library("fpp", lib.loc="C:/Users/HP/Anaconda3/envs/rstudio/lib/R/library")
library("ggplot2", lib.loc="C:/Users/HP/Anaconda3/envs/rstudio/lib/R/library")
library("xts", lib.loc="C:/Users/HP/Anaconda3/envs/rstudio/lib/R/library")
library("zoo", lib.loc="C:/Users/HP/Anaconda3/envs/rstudio/lib/R/library")
```

### Importing the data

```{r dataimport, echo=TRUE, message=FALSE, warning=FALSE}
setwd("D:/USMS/UChicago/STUDIES/Autumn 2020/MSCA 31006 1 Time Series Analysis and Forecasting/Final Project/Data")
page_2NE1_views <- data.matrix(read.csv("train_1.csv", header = TRUE, row.names = 1,sep = ",",nrows = 1,skip =0))
```

### Preparing data to make it ready for time-series


```{r tsready, echo=TRUE, message=FALSE, warning=FALSE}
# removing column names
dimnames(page_2NE1_views) <- NULL

# converting to array
page_2NE1_views <- array(page_2NE1_views)

# checking the values
head(page_2NE1_views)

# no. of ovservations
length(page_2NE1_views)
```

So, we see that there are 550 observations, i.e. number of views for the wikipedia page for 550 days from 1st July 2015 till 31st Dec 2016

Let's convert it to time-series and then split it to train and test - we will train our models for the period 1st July 2015 till 20th Dec 2016 and we will forecast for 21st Dec 2016 to 31st Dec 2016

```{r ts, echo=TRUE, message=FALSE, warning=FALSE}
# converting to time-series
time_index <- seq(from = as.POSIXct("2015-07-01"),to = as.POSIXct("2016-12-31"), by = "day")
page_2NE1_views_ts <- xts(page_2NE1_views, order.by =time_index ,frequency = 365.25)

# checking first few values
head(page_2NE1_views_ts)

# splitting to train and test
page_2NE1_views_ts_train <- page_2NE1_views_ts['2015-07-01/2016-12-20']
page_2NE1_views_ts_test <- page_2NE1_views_ts['2016-12-21/2016-12-31']

# viewing the train and test
head(page_2NE1_views_ts_train)
tail(page_2NE1_views_ts_train)
page_2NE1_views_ts_test
```

Now, let's look at our train data.

```{r trainlook, echo=TRUE, message=FALSE, warning=FALSE}
autoplot(page_2NE1_views_ts_train)
```

From the first look of the time-series, we see that there are few outliers. We see that after the occurence of this outlier, the level of the time-series did not change, hence this outlier **is not an intervention**. So, we can replace this value with the mean of all observations to maintain sanity.

We see, it is a bit better now, but few more outliers still left, let's treat them similarly as they do not cause any change in the level of the data.

```{r outlier2, echo=TRUE, message=FALSE, warning=FALSE}
# replacing the outlier with mean
page_2NE1_views_ts_train[page_2NE1_views_ts_train>=150]

page_2NE1_views_ts_train[page_2NE1_views_ts_train>150] <- mean(page_2NE1_views_ts_train[!page_2NE1_views_ts_train>=150])

# plotting
autoplot(page_2NE1_views_ts_train)
```

Looks much better now. But we that the variance is increasing over time, so transformation of data might be needed to de-couple variance from the mean.

Transforming the data -->

```{r transform, echo=TRUE, message=FALSE, warning=FALSE}
# finding ideal lambda
BoxCox.lambda(page_2NE1_views_ts_train)

# transforming the data
page_2NE1_views_ts_train_transformed <- BoxCox(page_2NE1_views_ts_train,lambda = -0.3565587)

# visualizing again
autoplot(page_2NE1_views_ts_train_transformed)
```

Few things we can notice about the time-series ->

1. It has a slight non-seasonal and long-term trend
2. Might be a hint of cyclical component
3. Seasonal component might be present.
4. The level does not seem constant over time


Now, let's look at the ACF and PACF for this time-series

```{r ACF, echo=TRUE, message=FALSE, warning=FALSE}
tsdisplay(page_2NE1_views_ts_train_transformed)
```

From the ACF/PACF we can see -->

1. There is very slow decay of the ACF which indicates this data is **NOT stationary**. There is a hint of sinusoidal component as well
2. There is decay of ACF and drop in PACF after lag 3, this might be an indication that we can apply AR model with order = 3

Applying KPSS test to check stationarity -->

```{r kpss, echo=TRUE, message=FALSE, warning=FALSE}
kpss.test(page_2NE1_views_ts_train_transformed)
```

The p-value = 0.01  
=> We reject the NULL hypothesis  
=> The data is **NOT stationary**

So, to handle the non-seasonal non-stationarity, let's apply 1 order of non-seasonal differencing

```{r nsdiff, echo=TRUE, message=FALSE, warning=FALSE}
# applying 1st order differencing
page_2NE1_views_ts_train_transformed_diff <- diff(page_2NE1_views_ts_train_transformed)

# visualizing data
tsdisplay(page_2NE1_views_ts_train_transformed_diff)
```

Now, we can see from time-series plot the data appears stationary. From the ACF, we can see that there is no more slow decay, which indicates it **is stationary**.

Let's confirm this with KPSS test

```{r kpss2, echo=TRUE, message=FALSE, warning=FALSE}
kpss.test(page_2NE1_views_ts_train_transformed_diff)
```

Here, p-value = 0.1  
=> The data **is stationary**

Applying auto.arima

```{r autoarima, echo=TRUE, message=FALSE, warning=FALSE}
auto.arima(page_2NE1_views_ts_train,lambda = "auto", d=1)
```

Applying the model suggested by auto.arima

```{r arima, echo=TRUE, message=FALSE, warning=FALSE}
m1 <- auto.arima(page_2NE1_views_ts_train,lambda = "auto", d=1)
m1
```

Forecasting

```{r forecast, echo=TRUE, message=FALSE, warning=FALSE}
forecast(m1,h=10)
```

Visualizing the forecast

```{r forecastv, echo=TRUE, message=FALSE, warning=FALSE}
plot(forecast(m1,h=10))
```

Checking model performance

```{r performance, echo=TRUE, message=FALSE, warning=FALSE}
accuracy(forecast(m1,h=10),page_2NE1_views_ts_test)
```

```{r others, echo=TRUE, message=FALSE, warning=FALSE}
Model_Mean <- meanf(page_2NE1_views_ts_train, h=10) 
Model_Naive <- naive(page_2NE1_views_ts_train, h=10) 
Model_Drift <- rwf(page_2NE1_views_ts_train, h=10, drift=TRUE)

accuracy(Model_Mean,page_2NE1_views_ts_test)
accuracy(Model_Naive,page_2NE1_views_ts_test)
accuracy(Model_Drift,page_2NE1_views_ts_test)
```

So, we see that our model test RMSE is better than that of all naive models.

Let's see how the residuals are.

```{r residuals, echo=TRUE, message=FALSE, warning=FALSE}
checkresiduals(m1)
```

From the time-series of the residuals, we see that its mean = 0 => our model is not biased.

From ACF plot, we see that the ACF of the residuals are almost white noise. There is no significant correlations between the residuals. This implies that our model performed well.There is one significant spike at lag 21. But I believe we can live with it.  
From the histogram, we can see that the residuals are fairly normally distributed.

Let's check the QQ plot as well

```{r qqplot, echo=TRUE, message=FALSE, warning=FALSE}
qqnorm(m1$residuals,main=expression(Normal~~Q-Q~~Plot))
qqline(m1$residuals)
```

The residuals seem to be fairly normally distributed with few outliers.

Now, let's try forecasting with ETS model and see how it turns out.

```{r ets, echo=TRUE, message=FALSE, warning=FALSE}
m2 <- ets(page_2NE1_views_ts_train,lambda = "auto")
m2
accuracy(forecast(m2,h=10),page_2NE1_views_ts_test)
```

We see that the test RMSE is kind of between that of ARMA model and the naive models.